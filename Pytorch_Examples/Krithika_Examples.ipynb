{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Linear(in_features: int, out_features: int, bias: bool = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_layer = nn.Linear(2, 2, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6615,  0.2790],\n",
       "        [-0.1878, -0.1082]], requires_grad=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_layer.weight\n",
    "lin_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_layer.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually set the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_layer.weight.data = torch.tensor([[1,2], [1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1, 2],\n",
       "        [1, 2]], requires_grad=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 2.],\n",
       "        [1., 2.]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_layer.weight = nn.Parameter(torch.ones(lin_layer.weight.shape))\n",
    "lin_layer.weight = nn.Parameter(torch.tensor([[1,2], [1, 2]], dtype=torch.float64))\n",
    "lin_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 11.], dtype=torch.float64, grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.tensor([[3,4], [3,4]], dtype=torch.float64)\n",
    "input_data = torch.tensor([3,4], dtype=torch.float64)\n",
    "\n",
    "output = lin_layer(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class f1:\n",
    "    def __init__(self, multiplier):\n",
    "        self.multiplier = multiplier\n",
    "    def get_multiplier_value(self):\n",
    "        return self.multiplier\n",
    "    \n",
    "    def __call__(self, number):\n",
    "        return number*self.multiplier\n",
    "\n",
    "a= f1(3)\n",
    "a.get_multiplier_value()\n",
    "\n",
    "a(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11, grad_fn=<DotBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_layer = nn.Linear(2, 1, bias=False)\n",
    "# manually set the weights\n",
    "lin_layer.weight.data = torch.tensor([1,2])\n",
    "input_data = torch.tensor([3,4])\n",
    "\n",
    "output = lin_layer(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11, grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Layer form\n",
    "relu = nn.ReLU()\n",
    "relu(output)\n",
    "\n",
    "relu(torch.tensor(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Function form\n",
    "F.relu(torch.tensor(-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=1, hidden_size=1, num_layers=1, nonlinearity='relu', bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3158]],\n",
       "\n",
       "        [[-1.0375]],\n",
       "\n",
       "        [[-0.6630]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.randn(3, 1, 1)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0744]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0 = torch.rand(1,1,1)\n",
    "h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4318]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, h_n = rnn(input_data, h_0)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcf2c2c2c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)    # reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = True   # set to True if haven't download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0eb6b159a148c5af25553c14513238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3605a7622d514cab850b1f0dac02761a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4292dba2d846a3a4ce6aac8b6f10af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27861c97194341628b3c1aa26300b52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Mnist digital dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader for easy mini-batch return in training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ardhendusingh/Applications/anaconda3/envs/local_nmt/lib/python3.6/site-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/ardhendusingh/Applications/anaconda3/envs/local_nmt/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ardhendusingh/Applications/anaconda3/envs/local_nmt/lib/python3.6/site-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\n",
    "test_x = Variable(test_data.test_data, volatile=True).type(torch.FloatTensor)[:2000]/255.\n",
    "# shape (2000, 28, 28) value in range(0,1)\n",
    "test_y = test_data.test_labels.numpy().squeeze()[:2000]    # covert to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.2607 | test accuracy: 0.10\n",
      "Epoch:  0 | train loss: 1.0006 | test accuracy: 0.54\n",
      "Epoch:  0 | train loss: 0.8141 | test accuracy: 0.69\n",
      "Epoch:  0 | train loss: 0.3652 | test accuracy: 0.80\n",
      "Epoch:  0 | train loss: 0.5855 | test accuracy: 0.85\n",
      "Epoch:  0 | train loss: 0.3440 | test accuracy: 0.88\n",
      "Epoch:  0 | train loss: 0.2780 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.4114 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1343 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.2064 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.0732 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1144 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.2560 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.4530 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.2869 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.2835 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0994 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1060 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.1261 | test accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = Variable(x.view(-1, 28, 28))              # reshape x to (batch, time_step, input_size)\n",
    "        b_y = Variable(y)                               # batch y\n",
    "\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)                   # (samples, time_step, input_size)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.item(), '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "# print 10 predictions from test data\n",
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NMT",
   "language": "python",
   "name": "nmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
