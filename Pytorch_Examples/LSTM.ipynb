{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#https://learning.oreilly.com/library/view/hands-on-natural-language/9781789802740/B12365_05_Final_JC_ePub.xhtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_sentiment/sentiment.txt\") as f:\n",
    "    reviews = f.read()\n",
    "    \n",
    "data = pd.DataFrame([review.split('\\t') for review in reviews.split('\\n')])\n",
    "\n",
    "data.columns = ['Review','Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...         0\n",
       "1  Not sure who was more lost - the flat characte...         0\n",
       "2  Attempting artiness with black & white and cle...         0\n",
       "3       Very little music or anything to speak of.           0\n",
       "4  The best scene in the movie was when Gerardo i...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data.shape\n",
    "data = data.sample(frac=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what is str.maketrans\n",
    "\n",
    "Parameter\tDescription\n",
    "\n",
    "- x\tRequired. If only one parameter is specified, this has to be a dictionary describing how to perform the replace. If two or more parameters are specified, this parameter has to be a string specifying the characters you want to replace.\n",
    "- y\tOptional. A string with the same length as parameter x. Each character in the first parameter will be replaced with the corresponding character in this string.\n",
    "- z\tOptional. A string describing which characters to remove from the original string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "## Example\n",
    "txt = \"Good night Sam!\";\n",
    "x = \"Sam\";\n",
    "y = \"Joe\";\n",
    "z = \"odnght\";\n",
    "\n",
    "\n",
    "mytable = str.maketrans('', '', z);\n",
    "\n",
    "print( mytable)\n",
    "\n",
    "print(txt.translate(mytable));\n",
    "\n",
    "mytable = str.maketrans(x, y, z);\n",
    "print(txt.translate(mytable));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if',\n",
       " 'i',\n",
       " 'take',\n",
       " 'a',\n",
       " 'picture',\n",
       " 'the',\n",
       " 'battery',\n",
       " 'drops',\n",
       " 'a',\n",
       " 'bar',\n",
       " 'and',\n",
       " 'starts',\n",
       " 'beeping',\n",
       " 'letting',\n",
       " 'me',\n",
       " 'know',\n",
       " 'its',\n",
       " 'dieing']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_words_reviews(data):\n",
    "    text = list(data['Review'].values)\n",
    "    clean_text = []\n",
    "    \n",
    "    # for each sentence, remove punctutations, lower, remove training space, and add \n",
    "    for t in text:\n",
    "        clean_text.append(t.translate(str.maketrans('', '', punctuation)).lower().rstrip())\n",
    "        \n",
    "        \n",
    "    # now each sentence is convtered to ['it', 'really', 'created', 'a', 'unique', 'feeling', 'though']\n",
    "    # tokenized is a list of list of tokens\n",
    "    tokenized = [word_tokenize(x) for x in clean_text]\n",
    "    \n",
    "    # all_text is mainly used for creating set\n",
    "    all_text = []\n",
    "    for tokens in tokenized:\n",
    "        for t in tokens:\n",
    "            all_text.append(t)\n",
    "    return tokenized, set(all_text)\n",
    "\n",
    "reviews, vocab = split_words_reviews(data)\n",
    "\n",
    "reviews[0]\n",
    "\n",
    "# this create a dictionary of 'elf': 3 and 3: 'elf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11.783666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dictionaries(words):\n",
    "    word_to_int_dict = {w:i+1 for i, w in enumerate(words)}\n",
    "    int_to_word_dict = {i:w for w, i in word_to_int_dict.items()}\n",
    "    return word_to_int_dict, int_to_word_dict\n",
    "\n",
    "word_to_int_dict, int_to_word_dict = create_dictionaries(vocab)\n",
    "\n",
    "int_to_word_dict[0] = ''\n",
    "word_to_int_dict[''] = 0\n",
    "\n",
    "## average lenght and max lenght of a sentence\n",
    "\n",
    "np.max([len(i) for i in reviews])\n",
    "np.mean([len(i) for i in reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'if',\n",
       "       'i', 'take', 'a', 'picture', 'the', 'battery', 'drops', 'a', 'bar',\n",
       "       'and', 'starts', 'beeping', 'letting', 'me', 'know', 'its',\n",
       "       'dieing'], dtype='<U33')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pad it:   If text lenght is less than 50, then prepend it with '' to make it 50\n",
    "\n",
    "def pad_text(tokenized_reviews, seq_length):\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for review in tokenized_reviews:\n",
    "        if len(review) >= seq_length:\n",
    "            reviews.append(review[:seq_length])\n",
    "        else:\n",
    "            reviews.append(['']*(seq_length-len(review)) + review)\n",
    "        \n",
    "    return np.array(reviews)\n",
    "\n",
    "padded_sentences = pad_text(reviews, seq_length = 50)\n",
    "\n",
    "padded_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 3315,\n",
       "       3702, 2224,  350, 4446, 1331, 2338, 2059,  350, 4206, 4443, 4379,\n",
       "       3871, 1656, 4845, 4461, 3605, 1800])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert word to int and then to np.array\n",
    "\n",
    "encoded_sentences = np.array([[word_to_int_dict[word] for word in review] for review in padded_sentences])\n",
    "\n",
    "# print first encoded sentences\n",
    "encoded_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# search 'Parameters for LSTM to train' in oneNote\n",
    "class MSentimentLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, n_hidden, n_output, n_layers, drop_p = 0.8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_vocab = n_vocab  \n",
    "        self.n_layers = n_layers \n",
    "        self.n_hidden = n_hidden \n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, dropout = drop_p)\n",
    "        \n",
    "\n",
    "\n",
    "mnet = MSentimentLSTM(n_vocab=5401, n_embed=50, n_hidden=100, n_output=1, n_layers=1)\n",
    "a = list(mnet.parameters())\n",
    "len(a)\n",
    "\n",
    "for i in mnet.named_parameters():\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{ll} \\\\\n",
    "i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\\n",
    "c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "h_t = o_t * \\tanh(c_t) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "For input data size 1 vector_size, 1 hidden size,\n",
    "- 4w input size + 4 bias and 4 previous_hidden_W + 4_bias = total 16 \n",
    "For input data size 1 vector_size, 2 hidden size,\n",
    "- 8w input size + 8 bias and 8 previous_hidden_W + 8_bias = total 32 \n",
    "\n",
    "For input data size 2 vector_size, 1 hidden size,\n",
    "- 8w input size + 4 bias and 4 previous_hidden_W + 8_bias = total 20\n",
    "\n",
    "\n",
    "\n",
    "where  `h_t` is the hidden state at time `t`,  `c_t` is the cell\n",
    "state at time `t`,  `x_t` is the input at time `t`,  `h_{(t-1)}`\n",
    "is the hidden state of the layer at time `t-1` or the initial hidden\n",
    "state at time `0`, and  `i_t`,  `f_t`,  `g_t`,\n",
    " `o_t` are the input, forget, cell, and output gates, respectively.\n",
    " `\\sigma` is the sigmoid function, and  `*` is the Hadamard product.\n",
    "\n",
    "\n",
    "In a multilayer LSTM, the input  `x^{(l)}_t` of the  `l` -th layer\n",
    "( `l >= 2`) is the hidden state  `h^{(l-1)}_t` of the previous layer multiplied by\n",
    "dropout  `\\delta^{(l-1)}_t` where each  `\\delta^{(l-1)}_t` is a Bernoulli random\n",
    "variable which is  `0` with probability :attr:`dropout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "lstm_l = nn.LSTM(input_size=2, hidden_size=1, num_layers=1, batch_first = True)\n",
    "a = list(lstm_l.parameters())\n",
    "len(a)\n",
    "\n",
    "    \n",
    "print()\n",
    "\n",
    "for i in lstm_l.named_parameters():\n",
    "    if 'weight_ih' in i[0]:\n",
    "        print('3-gates+1NC for input data: i_gate, f_gate, o_gate, nc_creation:',i[0], i[1].shape)\n",
    "    if 'weight_hh' in i[0]:\n",
    "        print('3-gates+1NC weights for previous hidden data: i_gate, f_gate, o_gate, nc_creation:',i[0], i[1].shape)\n",
    "    \n",
    "    if 'bias_ih' in i[0]:\n",
    "        print('bias for input data:', i[0], i[1].shape)\n",
    "    if 'bias_hh' in i[0]:\n",
    "        print('bias for previous hidden data:', i[0], i[1].shape)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "for i in lstm_l.named_parameters():\n",
    "    print(i[0], i[1].shape)\n",
    "\n",
    "print()\n",
    "\n",
    "for i in lstm_l.named_parameters():\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2400, 0.9, 2700)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get labels in an array\n",
    "# then number of rows in train and validation\n",
    "labels = np.array([int(x) for x in data['Sentiment'].values])\n",
    "\n",
    "train_ratio = 0.8\n",
    "valid_ratio = (1 - train_ratio)/2\n",
    "\n",
    "total = len(encoded_sentences)\n",
    "train_cutoff = int(total * train_ratio)\n",
    "valid_cutoff = int(total * (1 - valid_ratio))\n",
    "\n",
    "total, int(total * train_ratio), (1 - valid_ratio), int(total * (1 - valid_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now split data\n",
    "train_x, train_y = torch.Tensor(encoded_sentences[:train_cutoff]).long(), torch.Tensor(labels[:train_cutoff]).long()\n",
    "valid_x, valid_y = torch.Tensor(encoded_sentences[train_cutoff : valid_cutoff]).long(), torch.Tensor(labels[train_cutoff : valid_cutoff]).long()\n",
    "test_x, test_y = torch.Tensor(encoded_sentences[valid_cutoff:]).long(), torch.Tensor(labels[valid_cutoff:])\n",
    "\n",
    "train_data = TensorDataset(train_x, train_y)\n",
    "valid_data = TensorDataset(valid_x, valid_y)\n",
    "test_data = TensorDataset(test_x, test_y)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "#DataLoader allows us to batch process our datasets with the batch_size parameter, \n",
    "# allowing different batch sizes to be easily passed to our model.\n",
    "#In this instance, we will keep it simple and set batch_size = 1, which means our model will be trained on \n",
    "# individual sentences, rather than using larger batches of data. \n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the embedding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape=torch.Size([1, 50])\n",
      "label shape=torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         3431, 2349]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loop unrolling\n",
    "for inputs, labels in train_loader:\n",
    "    break\n",
    "\n",
    "print(f'input data shape={inputs.shape}\\nlabel shape={labels.shape}')\n",
    "\n",
    "inputs # one sentence\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of one sentences  torch.Size([1, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5401"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 40])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: 1 sentence of 60 words with pads. torch.Size([1, 60])\n",
    "# Output: 1 sentence 60 words and  50 dims for each word\n",
    "n_embed = 40\n",
    "print('length of one sentences ', inputs.shape)\n",
    "len(word_to_int_dict)\n",
    "embedding = nn.Embedding(len(word_to_int_dict), n_embed) # number of embedding dimension torch.Size([1, 60, 50])\n",
    "embedded_words = embedding(inputs)\n",
    "\n",
    "inputs.shape #torch.Size([1, 60])\n",
    "embedded_words.shape # torch.Size([1, 60, 40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for Input data\n",
      "Weights for 3-gates+1_New_Context for input data:\n",
      "\t\t i_gate, f_gate, o_gate, nc_creation: weight_ih_l0 torch.Size([40, 4])\n",
      "\n",
      "Weights for previous hidden data\n",
      "3-gates+1_New_Context weights for previous hidden data:\n",
      "\t\t i_gate, f_gate, o_gate, nc_creation: weight_hh_l0 torch.Size([40, 10])\n",
      "\n",
      "bias for input data: bias_ih_l0 torch.Size([40])\n",
      "bias for previous hidden data: bias_hh_l0 torch.Size([40])\n",
      "Weights for Input data\n",
      "Weights for 3-gates+1_New_Context for input data:\n",
      "\t\t i_gate, f_gate, o_gate, nc_creation: weight_ih_l1 torch.Size([40, 10])\n",
      "\n",
      "Weights for previous hidden data\n",
      "3-gates+1_New_Context weights for previous hidden data:\n",
      "\t\t i_gate, f_gate, o_gate, nc_creation: weight_hh_l1 torch.Size([40, 10])\n",
      "\n",
      "bias for input data: bias_ih_l1 torch.Size([40])\n",
      "bias for previous hidden data: bias_hh_l1 torch.Size([40])\n",
      "Weights for Input data\n",
      "Weights for 3-gates+1_New_Context for input data:\n",
      "\t\t i_gate, f_gate, o_gate, nc_creation: weight_ih_l2 torch.Size([40, 10])\n",
      "\n",
      "Weights for previous hidden data\n",
      "3-gates+1_New_Context weights for previous hidden data:\n",
      "\t\t i_gate, f_gate, o_gate, nc_creation: weight_hh_l2 torch.Size([40, 10])\n",
      "\n",
      "bias for input data: bias_ih_l2 torch.Size([40])\n",
      "bias for previous hidden data: bias_hh_l2 torch.Size([40])\n",
      "\n",
      "weight_ih_l0 torch.Size([40, 4])\n",
      "weight_hh_l0 torch.Size([40, 10])\n",
      "bias_ih_l0 torch.Size([40])\n",
      "bias_hh_l0 torch.Size([40])\n",
      "weight_ih_l1 torch.Size([40, 10])\n",
      "weight_hh_l1 torch.Size([40, 10])\n",
      "bias_ih_l1 torch.Size([40])\n",
      "bias_hh_l1 torch.Size([40])\n",
      "weight_ih_l2 torch.Size([40, 10])\n",
      "weight_hh_l2 torch.Size([40, 10])\n",
      "bias_ih_l2 torch.Size([40])\n",
      "bias_hh_l2 torch.Size([40])\n",
      "\n",
      "weight_ih_l0 Parameter containing:\n",
      "tensor([[-0.2057, -0.2459,  0.1395,  0.2044],\n",
      "        [ 0.1505, -0.0491, -0.1580, -0.0783],\n",
      "        [-0.0961, -0.0097, -0.1815,  0.0311],\n",
      "        [ 0.0216,  0.1522, -0.0527, -0.1258],\n",
      "        [ 0.0987, -0.2606,  0.2373,  0.0820],\n",
      "        [ 0.1789, -0.0232,  0.2447,  0.2050],\n",
      "        [ 0.2697, -0.0770, -0.1464, -0.0261],\n",
      "        [-0.2801, -0.1821,  0.1428, -0.0533],\n",
      "        [-0.2777, -0.2925, -0.1283,  0.1669],\n",
      "        [ 0.1134,  0.1540,  0.1458,  0.2758],\n",
      "        [-0.0373,  0.1278, -0.2783, -0.0271],\n",
      "        [-0.1561,  0.0119, -0.1859, -0.2208],\n",
      "        [ 0.0822,  0.0263, -0.3136,  0.2175],\n",
      "        [-0.0983,  0.2499,  0.1248, -0.0155],\n",
      "        [-0.2565,  0.1547,  0.2287, -0.2686],\n",
      "        [ 0.1997, -0.3054, -0.0520,  0.0985],\n",
      "        [-0.1656, -0.1777,  0.0450, -0.0345],\n",
      "        [-0.1345, -0.0466, -0.1881,  0.1414],\n",
      "        [ 0.2491,  0.2551,  0.0863, -0.2572],\n",
      "        [ 0.1481,  0.2128,  0.1811, -0.2313],\n",
      "        [-0.0441, -0.0227, -0.1070,  0.0279],\n",
      "        [ 0.2653, -0.2459,  0.2018, -0.1647],\n",
      "        [ 0.0457, -0.1325,  0.1741,  0.2997],\n",
      "        [ 0.2516,  0.2574,  0.0515, -0.1433],\n",
      "        [ 0.1464,  0.2209, -0.1213,  0.2359],\n",
      "        [-0.1661, -0.0845,  0.2348, -0.1381],\n",
      "        [-0.2636,  0.3139, -0.2444, -0.0853],\n",
      "        [-0.1553, -0.3144,  0.1865,  0.2644],\n",
      "        [ 0.1206, -0.0123, -0.1762,  0.2815],\n",
      "        [ 0.2008,  0.2060,  0.3155,  0.0860],\n",
      "        [-0.0188,  0.1822, -0.2669,  0.1717],\n",
      "        [-0.1053, -0.1197,  0.0918,  0.0874],\n",
      "        [ 0.2672, -0.1561,  0.0516, -0.0418],\n",
      "        [ 0.2102,  0.1473,  0.1828,  0.2114],\n",
      "        [ 0.0381, -0.2633,  0.2418, -0.2502],\n",
      "        [ 0.0179,  0.2547,  0.2364, -0.1848],\n",
      "        [ 0.1215, -0.2414, -0.1945,  0.2878],\n",
      "        [ 0.0208, -0.0133,  0.2637, -0.3130],\n",
      "        [-0.0280, -0.0157, -0.1296,  0.2332],\n",
      "        [-0.2632, -0.1118, -0.0367, -0.2099]], requires_grad=True)\n",
      "weight_hh_l0 Parameter containing:\n",
      "tensor([[ 0.2268, -0.0180, -0.1475, -0.1838, -0.1866, -0.1733,  0.2598,  0.2678,\n",
      "         -0.2690,  0.0255],\n",
      "        [ 0.2626, -0.2371, -0.0137,  0.0573,  0.2724, -0.1103,  0.2170, -0.0755,\n",
      "         -0.0421, -0.2514],\n",
      "        [-0.0332,  0.0520, -0.2800,  0.0219, -0.2562, -0.2041, -0.1348, -0.0542,\n",
      "         -0.0627,  0.0862],\n",
      "        [ 0.0346, -0.2718, -0.0758,  0.0902, -0.1615, -0.0759, -0.2926,  0.0350,\n",
      "         -0.1686,  0.2353],\n",
      "        [ 0.0532, -0.0028,  0.1786, -0.0716,  0.0517, -0.1808,  0.1701, -0.0169,\n",
      "          0.0210, -0.1886],\n",
      "        [ 0.2790,  0.2235,  0.2548, -0.2186, -0.0944,  0.2360, -0.0026, -0.1097,\n",
      "          0.0813,  0.0730],\n",
      "        [ 0.0058, -0.0452, -0.1899,  0.0714,  0.2053, -0.3100,  0.1131,  0.2553,\n",
      "         -0.1550, -0.0345],\n",
      "        [-0.2761, -0.2565, -0.1309,  0.2558, -0.1062, -0.1131,  0.0621, -0.0367,\n",
      "         -0.2450,  0.3043],\n",
      "        [ 0.2168,  0.0104, -0.1105, -0.3098, -0.0379,  0.3143,  0.1831, -0.0316,\n",
      "          0.1521,  0.0477],\n",
      "        [-0.1374,  0.1937, -0.1853,  0.0211, -0.2098, -0.0257,  0.2163,  0.0508,\n",
      "          0.2517,  0.1248],\n",
      "        [-0.1547, -0.0446, -0.0366,  0.2706, -0.0254,  0.2648, -0.0813, -0.0227,\n",
      "          0.1723,  0.0764],\n",
      "        [-0.2285, -0.2156,  0.2974, -0.2024,  0.2599,  0.2344,  0.2995,  0.0927,\n",
      "          0.0836,  0.1254],\n",
      "        [ 0.2155,  0.1944,  0.2841, -0.2352, -0.2241,  0.0082,  0.2304, -0.2318,\n",
      "         -0.2375, -0.2711],\n",
      "        [-0.1997, -0.0303,  0.1985, -0.0635,  0.2249,  0.2502,  0.1392,  0.3025,\n",
      "          0.0684, -0.1311],\n",
      "        [ 0.0612, -0.2545,  0.1222,  0.2905,  0.0238,  0.0754, -0.2315, -0.2828,\n",
      "          0.1951, -0.0992],\n",
      "        [-0.0013,  0.2233, -0.2752,  0.1276, -0.3137,  0.0172, -0.0993,  0.1251,\n",
      "          0.1682,  0.0969],\n",
      "        [ 0.3135, -0.0774,  0.3110,  0.1492, -0.0070,  0.1220, -0.0314, -0.1792,\n",
      "         -0.0584, -0.1208],\n",
      "        [ 0.2645, -0.0235,  0.1585,  0.1927,  0.0540, -0.1786, -0.0147,  0.0981,\n",
      "          0.0891, -0.0706],\n",
      "        [-0.1732,  0.1899,  0.3146,  0.1585, -0.2050,  0.0078, -0.3107,  0.0612,\n",
      "         -0.3118, -0.2434],\n",
      "        [ 0.0249,  0.2895,  0.0301, -0.2256,  0.0906, -0.0933,  0.1316,  0.2674,\n",
      "          0.0971,  0.3082],\n",
      "        [ 0.0321,  0.2673,  0.1501, -0.1037,  0.1114, -0.1616, -0.3051,  0.0026,\n",
      "          0.2770, -0.0795],\n",
      "        [-0.2356, -0.2294, -0.3077, -0.2337,  0.0556, -0.1147, -0.2706, -0.0199,\n",
      "         -0.2260, -0.2485],\n",
      "        [ 0.0254, -0.1794, -0.0202,  0.2277,  0.1337,  0.1686, -0.0059, -0.0831,\n",
      "         -0.0403,  0.1838],\n",
      "        [ 0.1805, -0.1877, -0.0039,  0.2796, -0.2141, -0.1559, -0.0344,  0.2139,\n",
      "          0.0739, -0.0352],\n",
      "        [ 0.0076,  0.2405,  0.0431, -0.0071,  0.2711,  0.1194, -0.2960, -0.1046,\n",
      "         -0.0645, -0.0792],\n",
      "        [-0.1916, -0.2539, -0.0262, -0.2416,  0.2132,  0.0804, -0.0206,  0.2773,\n",
      "         -0.1752,  0.0487],\n",
      "        [ 0.0254, -0.2557, -0.3013,  0.2404,  0.0658,  0.1933, -0.0849, -0.2185,\n",
      "         -0.2648,  0.2381],\n",
      "        [-0.2509, -0.0779,  0.2372, -0.2883, -0.3016, -0.1684,  0.0513,  0.1097,\n",
      "          0.3097, -0.1881],\n",
      "        [-0.2314, -0.0454, -0.0576,  0.2862,  0.2238,  0.2882, -0.1007, -0.0275,\n",
      "         -0.0459,  0.1451],\n",
      "        [ 0.2800, -0.2983, -0.2843, -0.2465, -0.2931,  0.2812,  0.0041, -0.1792,\n",
      "          0.1820,  0.1712],\n",
      "        [ 0.1493,  0.1774, -0.1159, -0.1839, -0.2670, -0.0502, -0.0433, -0.2228,\n",
      "          0.1429, -0.0698],\n",
      "        [ 0.1158,  0.0701,  0.1228,  0.0011, -0.0448,  0.1042,  0.2199, -0.0399,\n",
      "         -0.1451, -0.2661],\n",
      "        [ 0.1725, -0.0134,  0.2227,  0.2554,  0.0424, -0.1570,  0.1653,  0.0788,\n",
      "         -0.2473, -0.2764],\n",
      "        [ 0.1319, -0.2587,  0.2999,  0.0785,  0.2294,  0.2759, -0.0381, -0.2640,\n",
      "          0.0863, -0.0542],\n",
      "        [ 0.0728, -0.3004, -0.2575, -0.1269,  0.0300,  0.0583,  0.2555,  0.3066,\n",
      "         -0.2831, -0.3160],\n",
      "        [-0.2251,  0.2544,  0.1575,  0.1214, -0.2862, -0.0664,  0.1576,  0.3130,\n",
      "          0.2384, -0.1862],\n",
      "        [-0.0327, -0.2322,  0.2901, -0.0756, -0.0118,  0.0807,  0.0211, -0.1544,\n",
      "          0.0288, -0.2979],\n",
      "        [-0.1078, -0.2886,  0.0929, -0.2243, -0.0452,  0.0725, -0.1246,  0.0264,\n",
      "          0.2430,  0.2959],\n",
      "        [ 0.0162, -0.0949, -0.2929,  0.2489, -0.1483, -0.2699,  0.0123, -0.2422,\n",
      "         -0.1533,  0.2926],\n",
      "        [-0.1344,  0.1891,  0.2599,  0.0508,  0.1301, -0.1670,  0.1558,  0.2112,\n",
      "         -0.1633,  0.0804]], requires_grad=True)\n",
      "bias_ih_l0 Parameter containing:\n",
      "tensor([ 2.2907e-01, -2.2806e-01, -3.4748e-02,  2.0400e-01, -2.5632e-02,\n",
      "        -3.1559e-01,  3.9050e-02,  1.1130e-01,  4.8519e-02, -1.2593e-01,\n",
      "         1.8871e-01,  8.4818e-02,  5.8198e-02, -5.8462e-02, -3.5700e-02,\n",
      "        -2.5556e-01, -6.6501e-02,  2.9674e-01,  2.3141e-01,  4.3492e-02,\n",
      "        -3.0163e-01, -2.0826e-01,  2.7681e-01, -5.1347e-02, -2.3518e-01,\n",
      "         7.7105e-02, -2.3077e-01,  1.7931e-01,  6.6595e-02, -1.6057e-01,\n",
      "        -1.9319e-02, -2.0683e-01,  3.0643e-01, -2.4619e-01, -1.1400e-02,\n",
      "         1.6699e-01,  1.2515e-01, -2.4817e-01, -1.9506e-04,  1.8581e-01],\n",
      "       requires_grad=True)\n",
      "bias_hh_l0 Parameter containing:\n",
      "tensor([-0.2743, -0.2334, -0.2749,  0.2605, -0.2793,  0.1163,  0.2775, -0.0840,\n",
      "         0.2104, -0.0174, -0.1777, -0.0248,  0.3158,  0.2199,  0.0581, -0.0945,\n",
      "         0.1348, -0.0606, -0.0253,  0.1601, -0.0988,  0.1187,  0.0752,  0.1080,\n",
      "        -0.1852, -0.1727, -0.0366,  0.0668,  0.2169, -0.1192,  0.2405,  0.0421,\n",
      "         0.2815, -0.1800, -0.1753,  0.2428, -0.1598, -0.2279,  0.1117,  0.0277],\n",
      "       requires_grad=True)\n",
      "weight_ih_l1 Parameter containing:\n",
      "tensor([[ 0.2014, -0.1211, -0.0580, -0.2497,  0.1495, -0.1555, -0.0818, -0.1999,\n",
      "          0.1522, -0.1785],\n",
      "        [-0.0997, -0.1378,  0.1907,  0.3037, -0.3124,  0.2381, -0.1908, -0.1517,\n",
      "          0.0738, -0.1221],\n",
      "        [-0.0352,  0.1032, -0.2398, -0.1585, -0.1720,  0.1208,  0.2012,  0.2385,\n",
      "         -0.2322, -0.1603],\n",
      "        [ 0.2959,  0.2330, -0.2959,  0.1697,  0.0664,  0.2532, -0.2037, -0.2934,\n",
      "         -0.1920, -0.1150],\n",
      "        [-0.0609,  0.0743, -0.1219,  0.1620, -0.0624, -0.3095, -0.1724,  0.2635,\n",
      "          0.2386,  0.1979],\n",
      "        [-0.0138, -0.3002,  0.0953, -0.2247, -0.1878, -0.1963, -0.1420, -0.2300,\n",
      "         -0.0499, -0.0169],\n",
      "        [-0.0929,  0.2292, -0.2808, -0.0082, -0.3063,  0.2848, -0.3008, -0.2905,\n",
      "          0.0783,  0.1976],\n",
      "        [-0.2231, -0.1384,  0.3106, -0.0268,  0.0910,  0.2190,  0.0941,  0.2751,\n",
      "          0.0009,  0.1878],\n",
      "        [-0.2283,  0.2867, -0.2238,  0.1353,  0.2893, -0.1460,  0.2472,  0.2761,\n",
      "          0.1172,  0.2895],\n",
      "        [ 0.0184,  0.0981, -0.1444,  0.2117, -0.1127,  0.1784, -0.1841, -0.2834,\n",
      "          0.2220, -0.2647],\n",
      "        [ 0.2663,  0.2316,  0.3051,  0.0667, -0.1955,  0.3121, -0.1589,  0.1390,\n",
      "         -0.3153,  0.1437],\n",
      "        [ 0.1630, -0.0513, -0.3077, -0.2029, -0.1143, -0.2675,  0.2041,  0.1060,\n",
      "         -0.0421, -0.1296],\n",
      "        [-0.2033, -0.2461, -0.2579, -0.0797, -0.1387, -0.2873, -0.2526,  0.1531,\n",
      "         -0.1662,  0.0045],\n",
      "        [ 0.1872,  0.1667,  0.2181,  0.0074,  0.0479, -0.1730,  0.0929,  0.1730,\n",
      "          0.0818, -0.2911],\n",
      "        [-0.0197, -0.0290, -0.2703, -0.2465,  0.2522, -0.0393,  0.2507, -0.1525,\n",
      "         -0.1443,  0.2165],\n",
      "        [ 0.0964, -0.3082, -0.2820, -0.0922, -0.1267,  0.0510,  0.0741,  0.1837,\n",
      "         -0.1556,  0.1458],\n",
      "        [ 0.0996, -0.0483,  0.0850, -0.2553,  0.0935, -0.0711, -0.0637, -0.1319,\n",
      "         -0.0144,  0.0776],\n",
      "        [ 0.2203,  0.0816, -0.0504,  0.2715, -0.0992,  0.2530, -0.0222, -0.2814,\n",
      "         -0.2112,  0.1055],\n",
      "        [-0.1250, -0.0623, -0.2744,  0.0397,  0.2001,  0.0756,  0.1183,  0.0924,\n",
      "         -0.0906, -0.1117],\n",
      "        [-0.1675, -0.0488,  0.0016,  0.2986,  0.0517, -0.1364,  0.1478,  0.1523,\n",
      "         -0.1342,  0.0490],\n",
      "        [-0.1258, -0.1122,  0.0963, -0.0279, -0.0205,  0.1151, -0.2696,  0.2835,\n",
      "          0.0934,  0.0673],\n",
      "        [ 0.0047, -0.2056,  0.2675,  0.0279,  0.1087,  0.1989,  0.2479, -0.3025,\n",
      "         -0.1642,  0.1374],\n",
      "        [ 0.1392, -0.0304, -0.1132,  0.1473, -0.1437,  0.1932,  0.0942, -0.1740,\n",
      "         -0.2749,  0.0673],\n",
      "        [-0.1168, -0.2506, -0.0664, -0.2671,  0.1178, -0.1324, -0.2636,  0.2891,\n",
      "         -0.2391, -0.3112],\n",
      "        [ 0.2879, -0.1918,  0.0040,  0.1304,  0.2767,  0.3033,  0.0288, -0.0910,\n",
      "         -0.1901, -0.1664],\n",
      "        [ 0.2343,  0.0350,  0.3018, -0.2333,  0.0477,  0.2258, -0.1740, -0.1624,\n",
      "         -0.0920,  0.1835],\n",
      "        [-0.1699,  0.2025,  0.2436,  0.0263,  0.0284,  0.1446, -0.2811,  0.1164,\n",
      "          0.0300,  0.0536],\n",
      "        [-0.2010, -0.2229,  0.1856,  0.0940,  0.0152,  0.0061,  0.2367,  0.2289,\n",
      "          0.0435,  0.1590],\n",
      "        [-0.2383, -0.3091, -0.2869,  0.1143,  0.1952,  0.2283,  0.2339,  0.0058,\n",
      "          0.2245,  0.1484],\n",
      "        [ 0.2852,  0.1633,  0.1789, -0.3096, -0.2656,  0.0805,  0.2054, -0.0146,\n",
      "          0.0957, -0.2526],\n",
      "        [ 0.0513,  0.2965,  0.2527,  0.2966, -0.2787,  0.1254,  0.2607,  0.0546,\n",
      "         -0.1821,  0.2349],\n",
      "        [ 0.1135, -0.1102,  0.0897,  0.2447, -0.2268,  0.0366, -0.1868,  0.3145,\n",
      "         -0.1749, -0.1655],\n",
      "        [-0.2037, -0.0398,  0.0579,  0.1087, -0.0196,  0.1717, -0.0999,  0.1165,\n",
      "         -0.1437, -0.1472],\n",
      "        [-0.1682, -0.0022,  0.0397, -0.2760,  0.1381, -0.1584,  0.0008,  0.2265,\n",
      "         -0.0425, -0.2472],\n",
      "        [-0.2369,  0.0615, -0.2972,  0.1164,  0.0905,  0.2750, -0.2594,  0.2742,\n",
      "         -0.1087,  0.1164],\n",
      "        [ 0.3007,  0.2987, -0.2065, -0.1865,  0.1592,  0.2403,  0.1768, -0.1668,\n",
      "          0.1554, -0.0841],\n",
      "        [ 0.2934, -0.2339,  0.2116, -0.3067,  0.1211, -0.1652, -0.1203,  0.0486,\n",
      "         -0.2897, -0.2666],\n",
      "        [-0.3074, -0.2088, -0.0793, -0.0430, -0.3082, -0.0093, -0.2714,  0.2232,\n",
      "         -0.0291,  0.1895],\n",
      "        [-0.1592, -0.0904, -0.0417,  0.1259, -0.2400, -0.0423,  0.0015, -0.1458,\n",
      "         -0.2050,  0.0218],\n",
      "        [ 0.3061, -0.0183,  0.2932, -0.1301,  0.2829, -0.0293, -0.2916,  0.0953,\n",
      "          0.1493, -0.0587]], requires_grad=True)\n",
      "weight_hh_l1 Parameter containing:\n",
      "tensor([[ 0.1476, -0.0551,  0.2882,  0.0422,  0.0187,  0.0022,  0.0894, -0.2526,\n",
      "          0.3116, -0.1618],\n",
      "        [ 0.2376,  0.1352, -0.2652,  0.2206,  0.2239, -0.0581, -0.1325,  0.2236,\n",
      "         -0.3108, -0.2255],\n",
      "        [-0.0915, -0.0922, -0.1449, -0.2195,  0.1301, -0.2221,  0.2173, -0.3049,\n",
      "         -0.0581, -0.1878],\n",
      "        [-0.3137, -0.2063,  0.1555,  0.0022,  0.2893,  0.2773, -0.1340, -0.2100,\n",
      "          0.1577, -0.0923],\n",
      "        [ 0.2874,  0.1424, -0.2945,  0.1474,  0.2143, -0.2893,  0.0553,  0.0373,\n",
      "          0.1712,  0.2669],\n",
      "        [ 0.2553,  0.1464, -0.2651,  0.0130, -0.2010, -0.2720,  0.1010, -0.2031,\n",
      "          0.3014,  0.2672],\n",
      "        [-0.0395,  0.1242, -0.1965,  0.0018, -0.0203,  0.2447,  0.0409, -0.3121,\n",
      "         -0.0432,  0.0380],\n",
      "        [ 0.2171,  0.3056,  0.1791,  0.1560, -0.2126,  0.0191,  0.1571,  0.2136,\n",
      "         -0.0029,  0.0863],\n",
      "        [ 0.1959, -0.1507, -0.0627, -0.0291,  0.0450,  0.2635,  0.0624,  0.3054,\n",
      "         -0.1859, -0.1531],\n",
      "        [ 0.1257,  0.0593,  0.0274,  0.1000, -0.1435, -0.1276,  0.2353, -0.0920,\n",
      "          0.0910, -0.3144],\n",
      "        [ 0.2805, -0.1046,  0.0502, -0.0073,  0.2362,  0.3036, -0.1356,  0.0036,\n",
      "          0.2168, -0.0564],\n",
      "        [-0.0761, -0.1576,  0.1525,  0.0735, -0.1916,  0.1814,  0.0879, -0.2754,\n",
      "          0.0092,  0.0582],\n",
      "        [ 0.1208,  0.2785, -0.0588,  0.2609,  0.0864, -0.3063, -0.2104, -0.1522,\n",
      "          0.2978,  0.1984],\n",
      "        [-0.1105, -0.0240, -0.0092,  0.2003,  0.1054, -0.1405,  0.0404,  0.1837,\n",
      "         -0.1890, -0.2051],\n",
      "        [ 0.1662,  0.1232,  0.0047,  0.2721,  0.2667,  0.1736,  0.0793, -0.1682,\n",
      "         -0.0125, -0.1567],\n",
      "        [ 0.1640, -0.1259, -0.1595,  0.0997,  0.1408, -0.0551, -0.0036,  0.1588,\n",
      "          0.2635, -0.2560],\n",
      "        [ 0.0702,  0.1097,  0.3114,  0.2085, -0.0302, -0.2730,  0.0126, -0.3088,\n",
      "         -0.2584,  0.2209],\n",
      "        [ 0.0862, -0.1795, -0.0353,  0.2978, -0.0069, -0.0485,  0.1047, -0.2107,\n",
      "          0.2475, -0.2905],\n",
      "        [ 0.0231, -0.0578, -0.0763,  0.1624, -0.0986, -0.0853,  0.2319,  0.2168,\n",
      "          0.0813, -0.3023],\n",
      "        [-0.2993, -0.0907,  0.2980,  0.3018, -0.0865, -0.1014, -0.2226,  0.2126,\n",
      "         -0.0949,  0.2082],\n",
      "        [-0.0071, -0.0973, -0.1327, -0.2879, -0.0442, -0.0987,  0.2895, -0.3060,\n",
      "          0.0339,  0.0742],\n",
      "        [-0.2870,  0.0121,  0.2286, -0.1325, -0.1628,  0.2468, -0.3001,  0.1932,\n",
      "         -0.0546,  0.2165],\n",
      "        [-0.2929,  0.2406, -0.2008, -0.2578,  0.2708,  0.0851,  0.0903,  0.1636,\n",
      "          0.2077, -0.2496],\n",
      "        [-0.2492,  0.1923, -0.1785,  0.2625, -0.1776,  0.2550, -0.1191, -0.1407,\n",
      "          0.1771,  0.2260],\n",
      "        [-0.0932,  0.1866, -0.2300, -0.0089,  0.2749,  0.0626,  0.0873, -0.2634,\n",
      "          0.1518,  0.0866],\n",
      "        [ 0.1037,  0.1381, -0.0397, -0.0311, -0.0253, -0.3035, -0.2790, -0.3039,\n",
      "         -0.0722, -0.0251],\n",
      "        [-0.2269,  0.1897, -0.1662,  0.1498, -0.2175, -0.1771, -0.0670,  0.0311,\n",
      "          0.1964,  0.1909],\n",
      "        [-0.2259, -0.0267, -0.1359,  0.2210,  0.2386,  0.0389, -0.1870, -0.0150,\n",
      "          0.2777,  0.0441],\n",
      "        [-0.1801, -0.0147, -0.1753,  0.1514,  0.0106,  0.1538, -0.0130,  0.2107,\n",
      "         -0.1393,  0.2678],\n",
      "        [-0.1453, -0.0678, -0.1244, -0.1301, -0.2294, -0.2776, -0.2465,  0.0922,\n",
      "          0.0959, -0.2827],\n",
      "        [-0.2910,  0.0633,  0.1871,  0.0014, -0.0993, -0.2313,  0.1254,  0.1291,\n",
      "          0.2335, -0.3048],\n",
      "        [-0.2414, -0.2284, -0.2586, -0.1296,  0.1968,  0.1219,  0.0507, -0.0304,\n",
      "          0.1558, -0.0234],\n",
      "        [-0.1748,  0.0675, -0.1578,  0.3007,  0.2519, -0.2397,  0.0963,  0.1540,\n",
      "          0.0676,  0.1098],\n",
      "        [ 0.0591, -0.0050,  0.1266, -0.1461,  0.0968,  0.1667, -0.1834,  0.2381,\n",
      "          0.2270, -0.2534],\n",
      "        [-0.2138, -0.1107,  0.0265, -0.3042, -0.1766, -0.2588,  0.1685, -0.2337,\n",
      "          0.2338, -0.1688],\n",
      "        [ 0.2901,  0.2844, -0.0935, -0.1184, -0.2371, -0.2999,  0.1267, -0.2484,\n",
      "          0.1255, -0.0968],\n",
      "        [-0.2132, -0.0240,  0.1921, -0.1950,  0.2975, -0.2479, -0.2991, -0.1898,\n",
      "         -0.2584,  0.2730],\n",
      "        [ 0.0701,  0.1510,  0.0740,  0.0312,  0.2100, -0.2931, -0.1145, -0.0333,\n",
      "          0.2644,  0.2394],\n",
      "        [ 0.1530,  0.1047,  0.0682, -0.0303, -0.0567,  0.0010, -0.0206,  0.3136,\n",
      "          0.1636,  0.2487],\n",
      "        [ 0.3048,  0.0805,  0.2609,  0.0395, -0.1662, -0.0914,  0.2219,  0.1908,\n",
      "          0.0099,  0.2925]], requires_grad=True)\n",
      "bias_ih_l1 Parameter containing:\n",
      "tensor([-0.0571,  0.2941, -0.1016,  0.0602,  0.2879, -0.0855, -0.2574,  0.2189,\n",
      "         0.2311, -0.1722,  0.0564, -0.2084, -0.3016,  0.0555, -0.2098, -0.1971,\n",
      "         0.0294, -0.0061, -0.0846, -0.2355, -0.0990,  0.0128, -0.0064, -0.0629,\n",
      "        -0.2564,  0.2186,  0.2499, -0.0999, -0.2902,  0.0818,  0.1205,  0.0345,\n",
      "        -0.1057,  0.3132,  0.2391,  0.2891, -0.2874,  0.1724,  0.0829,  0.0531],\n",
      "       requires_grad=True)\n",
      "bias_hh_l1 Parameter containing:\n",
      "tensor([ 0.2173,  0.0183,  0.2168,  0.2293,  0.0454, -0.2410,  0.2583,  0.2643,\n",
      "         0.0420,  0.1779, -0.0773, -0.2470, -0.1941, -0.0459,  0.0682, -0.0607,\n",
      "        -0.1748,  0.2421,  0.2137,  0.2327,  0.0424,  0.0157, -0.1560, -0.3043,\n",
      "         0.1127,  0.2285, -0.2123,  0.0260,  0.2958, -0.2781,  0.3052,  0.2421,\n",
      "         0.0038, -0.1074,  0.1780, -0.0391,  0.2839,  0.1106,  0.0802,  0.1119],\n",
      "       requires_grad=True)\n",
      "weight_ih_l2 Parameter containing:\n",
      "tensor([[ 1.6204e-01, -1.1461e-01, -1.2828e-01, -2.7302e-01, -1.7542e-01,\n",
      "         -2.7671e-01,  1.2244e-01, -8.0262e-02, -3.0317e-01, -1.8498e-01],\n",
      "        [-1.4339e-01, -2.3142e-01, -3.6206e-02, -2.5040e-01,  1.2138e-01,\n",
      "          9.7752e-02,  3.0426e-01, -1.8338e-02, -2.9959e-01,  2.6539e-01],\n",
      "        [-1.6104e-01,  1.3455e-01,  3.8967e-02, -1.2387e-01,  3.3488e-02,\n",
      "          1.3771e-01, -1.7789e-01, -1.2669e-01, -2.0291e-01,  1.4877e-01],\n",
      "        [ 6.3501e-02, -7.8754e-02, -1.3951e-01,  1.9331e-01, -1.7541e-02,\n",
      "          2.8132e-01, -1.1035e-01, -5.9771e-02,  5.7352e-02, -2.0349e-01],\n",
      "        [ 2.3904e-01,  2.8360e-01,  6.5200e-02, -2.1526e-01,  1.4844e-01,\n",
      "         -3.0731e-01, -2.9863e-01,  2.4865e-01,  9.3761e-03,  1.3935e-01],\n",
      "        [ 2.0683e-02, -3.9971e-02,  1.4367e-01, -1.4017e-01, -1.9823e-01,\n",
      "          2.4017e-01,  1.1185e-01, -1.4799e-01, -1.5961e-01, -2.3557e-01],\n",
      "        [ 2.7730e-01,  2.7370e-01,  1.4359e-01, -2.2911e-01,  3.4571e-06,\n",
      "          1.6055e-01,  3.1580e-01, -1.4418e-01, -4.8140e-02,  2.3861e-03],\n",
      "        [-1.1543e-01, -2.3754e-01, -5.0487e-02,  9.1260e-02,  3.0453e-02,\n",
      "          4.6967e-02, -1.2633e-01, -2.0253e-01, -1.7710e-02,  3.0345e-01],\n",
      "        [ 2.3893e-01, -7.5100e-02, -1.0205e-01, -2.6414e-02, -1.0610e-01,\n",
      "         -1.0579e-01,  1.0500e-01, -2.4525e-01,  2.6162e-01, -1.1642e-01],\n",
      "        [ 1.7334e-01, -1.0265e-01,  1.6058e-02,  2.1321e-02, -2.6990e-01,\n",
      "          1.7752e-01, -6.2107e-02,  1.8276e-01,  2.7904e-01, -7.9639e-02],\n",
      "        [ 8.9948e-02, -2.9273e-01,  2.7347e-01,  2.1338e-01, -1.8481e-01,\n",
      "         -2.2440e-01,  2.8854e-01, -1.6478e-01, -5.3168e-02, -2.8242e-01],\n",
      "        [-2.1012e-01,  8.5999e-02,  1.3399e-01,  3.0512e-01, -7.0744e-02,\n",
      "         -5.8401e-02,  1.5720e-01,  1.2154e-01,  9.8242e-02, -1.4110e-01],\n",
      "        [-1.5834e-01,  2.0814e-01, -2.6185e-01,  1.6626e-01, -2.6506e-01,\n",
      "         -1.0604e-01,  2.6851e-01,  2.7014e-01, -9.5955e-02, -1.8883e-01],\n",
      "        [ 6.3421e-02, -2.9454e-01,  1.0644e-01, -3.0653e-02, -6.7540e-03,\n",
      "         -3.7829e-02,  1.7762e-01, -3.7487e-02, -2.7246e-01, -9.1995e-02],\n",
      "        [-4.8610e-02,  2.3892e-01, -1.6227e-01,  2.1281e-01,  3.0596e-01,\n",
      "         -5.1819e-02,  1.5977e-01,  1.0345e-01, -1.1171e-01,  2.9552e-01],\n",
      "        [ 7.4260e-02,  2.8706e-01,  6.6591e-02,  7.5977e-02,  1.3397e-01,\n",
      "          3.1678e-02, -7.7787e-02,  2.4636e-01, -1.6746e-01,  1.1348e-01],\n",
      "        [ 3.1087e-01, -7.0754e-02,  2.9649e-01, -1.5513e-02,  1.1044e-01,\n",
      "         -9.2705e-02,  5.4252e-02, -4.7065e-02,  3.1445e-01, -3.6396e-02],\n",
      "        [-1.8937e-02, -2.2003e-01, -2.4248e-02,  2.9287e-01,  1.4030e-01,\n",
      "         -2.2335e-01, -1.5029e-01,  1.6592e-02,  3.1368e-01, -2.6436e-02],\n",
      "        [-1.5877e-01,  3.1365e-01, -1.1329e-01,  2.4361e-01, -1.0935e-01,\n",
      "         -1.2934e-01,  1.7508e-01, -7.3533e-02, -1.7967e-01,  4.9872e-03],\n",
      "        [-3.5207e-02,  2.6781e-01,  2.8626e-01, -1.1148e-02,  2.8573e-01,\n",
      "          3.0670e-01,  7.9635e-02,  2.3936e-01, -7.7428e-02,  7.5671e-02],\n",
      "        [ 4.3283e-02,  1.5107e-02,  4.7696e-04, -2.5526e-01,  2.1638e-01,\n",
      "          2.3388e-01,  9.1874e-02, -1.8982e-01, -3.1619e-01, -4.4432e-02],\n",
      "        [-2.4937e-01, -1.6566e-01, -5.3726e-03,  1.3767e-01, -1.5322e-01,\n",
      "          2.6782e-01, -1.7576e-01, -1.7328e-01, -2.3475e-01,  1.4397e-01],\n",
      "        [ 2.5889e-01,  5.8031e-02, -7.1023e-02,  3.1003e-01, -1.8705e-01,\n",
      "          5.8557e-02,  9.7258e-02,  1.6329e-01, -3.0603e-01, -5.6392e-02],\n",
      "        [ 1.4003e-01,  1.0388e-01, -7.3391e-02, -1.1428e-02,  2.4041e-01,\n",
      "          1.6263e-01,  3.0348e-01,  2.0662e-01, -2.5809e-02, -2.8280e-01],\n",
      "        [-1.3989e-01, -7.8199e-02,  1.5584e-01, -2.6769e-01,  1.7304e-01,\n",
      "          1.6871e-01,  4.3033e-02, -1.2829e-01,  1.8196e-01,  2.2171e-01],\n",
      "        [ 1.2966e-01,  1.7131e-01, -2.5857e-01, -1.1872e-01,  6.6742e-02,\n",
      "         -6.0079e-02, -8.7625e-02,  2.1912e-01,  2.9322e-01,  1.6130e-01],\n",
      "        [ 1.6248e-01,  8.0930e-03, -2.1759e-01,  2.2885e-01, -2.5152e-01,\n",
      "          1.5879e-01,  2.2574e-01,  9.3277e-02, -1.0105e-01, -1.5749e-01],\n",
      "        [ 3.5353e-02,  9.4920e-02, -1.8941e-01, -1.7770e-02,  9.3228e-02,\n",
      "          3.0115e-01, -1.0776e-01, -1.0773e-01, -7.3515e-02,  1.9274e-01],\n",
      "        [-1.7512e-01, -1.5466e-01,  1.9330e-01, -3.0657e-02, -1.6740e-01,\n",
      "         -4.0146e-02, -6.8692e-02, -3.1025e-01, -2.2918e-01,  2.9706e-01],\n",
      "        [-5.2950e-02, -1.6507e-01,  3.0472e-01,  2.1488e-02,  1.9936e-01,\n",
      "          1.7320e-01,  4.8363e-02,  3.8172e-02,  2.8488e-01, -5.7007e-02],\n",
      "        [ 9.6961e-02, -1.2912e-01,  7.1918e-02,  2.3615e-01,  2.4013e-01,\n",
      "          2.7250e-01,  2.7901e-01,  1.2900e-01,  2.8049e-01, -9.1752e-02],\n",
      "        [-5.5764e-02,  1.5326e-01, -2.7073e-01, -2.3014e-01, -2.7214e-01,\n",
      "          1.6755e-01,  2.0346e-01,  2.5284e-01, -2.1071e-01,  2.4315e-01],\n",
      "        [-5.0167e-02,  3.1490e-01, -3.0086e-01, -1.5953e-01,  2.0125e-01,\n",
      "          5.2762e-02, -2.0915e-02, -1.7686e-01, -1.3354e-01, -2.9952e-01],\n",
      "        [-2.9340e-01, -9.9746e-02,  2.3132e-01,  1.8045e-01, -2.6220e-01,\n",
      "          4.0461e-02,  3.0638e-01,  2.2991e-01, -1.2084e-01, -1.8959e-01],\n",
      "        [-5.5007e-02, -3.1388e-01,  6.9321e-02, -9.1425e-02, -5.9862e-02,\n",
      "          6.4307e-02,  2.6410e-01, -1.5462e-01, -1.8981e-01, -2.2107e-01],\n",
      "        [ 1.5219e-01, -2.9383e-01,  3.0444e-02,  3.0008e-01, -1.4925e-01,\n",
      "         -9.9080e-02,  3.0284e-01, -1.0289e-01, -1.8437e-01, -1.3476e-01],\n",
      "        [ 1.3540e-01, -2.8692e-02,  1.5763e-01,  2.8121e-01,  7.3574e-02,\n",
      "         -6.0043e-02,  1.1400e-01, -2.2102e-01,  1.2315e-02, -2.4089e-01],\n",
      "        [-8.8168e-02,  2.4330e-01,  5.1739e-02,  2.6502e-02,  1.1705e-01,\n",
      "         -1.1483e-01,  1.8225e-01,  1.3774e-02, -5.7579e-02, -4.3719e-02],\n",
      "        [ 1.7506e-01,  1.4549e-01, -1.0381e-01, -1.1763e-01, -2.2468e-01,\n",
      "          5.6341e-02,  1.7043e-01,  8.5178e-02, -7.1148e-02,  1.9475e-01],\n",
      "        [-1.0973e-01, -2.9416e-01, -3.1965e-02, -2.6970e-01, -3.6692e-02,\n",
      "         -2.5344e-01, -1.4396e-01, -6.9642e-02,  2.7311e-01, -1.6983e-01]],\n",
      "       requires_grad=True)\n",
      "weight_hh_l2 Parameter containing:\n",
      "tensor([[-0.2479,  0.2853, -0.1320, -0.0163,  0.1929,  0.2769,  0.2681, -0.0613,\n",
      "          0.1800,  0.1060],\n",
      "        [-0.2537, -0.1598,  0.1024,  0.1582,  0.0343, -0.1757,  0.1971,  0.0308,\n",
      "          0.1235, -0.2394],\n",
      "        [-0.0559, -0.3000, -0.1114,  0.2838, -0.1614,  0.0557,  0.2449,  0.0856,\n",
      "          0.2489, -0.1512],\n",
      "        [-0.1838, -0.2710, -0.1426,  0.2247, -0.1368, -0.2024, -0.0039, -0.1012,\n",
      "         -0.3032,  0.0783],\n",
      "        [-0.0030, -0.0602,  0.0383,  0.0539, -0.1976, -0.1075, -0.1253,  0.1216,\n",
      "         -0.0459, -0.2422],\n",
      "        [-0.0926, -0.0730,  0.0389,  0.1279,  0.0522,  0.2622, -0.0582, -0.2059,\n",
      "         -0.1931,  0.2599],\n",
      "        [-0.1543, -0.2824, -0.2267,  0.1692, -0.2021,  0.1190,  0.1053,  0.3017,\n",
      "         -0.0658,  0.2362],\n",
      "        [ 0.2755, -0.1593, -0.3148, -0.0112, -0.1081,  0.2199,  0.2084, -0.1164,\n",
      "         -0.1534,  0.0263],\n",
      "        [ 0.2071,  0.1222, -0.0806,  0.2965, -0.2773, -0.1114,  0.1115, -0.1001,\n",
      "          0.1950,  0.2382],\n",
      "        [ 0.0425, -0.0214,  0.2352, -0.2212,  0.3049,  0.0620,  0.2082, -0.2953,\n",
      "          0.1614, -0.2696],\n",
      "        [ 0.0413, -0.2217,  0.1533, -0.0896,  0.3030, -0.2818, -0.2565,  0.2228,\n",
      "          0.1897,  0.2414],\n",
      "        [-0.2352,  0.2347,  0.0696,  0.2292, -0.1066, -0.1285, -0.0684,  0.0182,\n",
      "          0.1917,  0.2561],\n",
      "        [ 0.3126, -0.2922, -0.1318, -0.0299, -0.0920,  0.0765, -0.2619,  0.0749,\n",
      "         -0.2733,  0.0687],\n",
      "        [-0.0072,  0.0932,  0.2696,  0.1746,  0.0328,  0.0969,  0.3101,  0.0304,\n",
      "         -0.1102, -0.0439],\n",
      "        [ 0.0371,  0.2043, -0.1931,  0.2430, -0.0074,  0.1900, -0.0407, -0.1689,\n",
      "          0.0068, -0.0371],\n",
      "        [-0.2783, -0.2523, -0.2016,  0.2715,  0.0691, -0.1732,  0.2595,  0.2913,\n",
      "          0.0299,  0.1650],\n",
      "        [-0.3001, -0.0441, -0.2494, -0.2815, -0.2565, -0.2621,  0.0869,  0.1725,\n",
      "         -0.1207, -0.2036],\n",
      "        [ 0.2379, -0.0054, -0.0759,  0.2195,  0.1108,  0.0173, -0.1217,  0.1860,\n",
      "         -0.0215,  0.0789],\n",
      "        [ 0.0059,  0.1308,  0.1350, -0.1781,  0.2792,  0.1035,  0.2652,  0.1940,\n",
      "          0.1290, -0.3143],\n",
      "        [-0.1209, -0.2983, -0.0743, -0.1341, -0.3019,  0.2988, -0.0296, -0.1724,\n",
      "         -0.2049, -0.1507],\n",
      "        [ 0.2353, -0.2475,  0.2475,  0.3087, -0.1019,  0.2274,  0.1936, -0.1158,\n",
      "         -0.0424, -0.1808],\n",
      "        [-0.0454, -0.1922, -0.2557, -0.0059,  0.0568, -0.1979, -0.1068, -0.2279,\n",
      "          0.2428, -0.1853],\n",
      "        [-0.1105,  0.2928, -0.1914, -0.2482,  0.1342, -0.3032,  0.2639,  0.0664,\n",
      "          0.1181,  0.0519],\n",
      "        [ 0.2469,  0.0651,  0.0954, -0.1159, -0.3045, -0.1115,  0.0576, -0.1591,\n",
      "         -0.1534, -0.2779],\n",
      "        [ 0.1237, -0.3059, -0.0973, -0.1181,  0.2681,  0.2648, -0.0620, -0.0122,\n",
      "          0.2138, -0.1400],\n",
      "        [ 0.1376, -0.0204, -0.1673, -0.2902,  0.1400,  0.2580, -0.2690,  0.1044,\n",
      "         -0.2409, -0.1720],\n",
      "        [ 0.1773,  0.2423,  0.0384,  0.2621, -0.2159, -0.2982,  0.0250,  0.2448,\n",
      "          0.0494, -0.2722],\n",
      "        [-0.3022,  0.1980, -0.0034, -0.1748, -0.2065,  0.2509,  0.2921, -0.1996,\n",
      "          0.0293, -0.0788],\n",
      "        [-0.2379,  0.2510,  0.1223,  0.1531,  0.1353, -0.2051,  0.2086, -0.1807,\n",
      "         -0.1424,  0.2369],\n",
      "        [-0.3042, -0.0815,  0.1770,  0.1255,  0.1754, -0.2498,  0.0796, -0.1892,\n",
      "          0.2223,  0.2132],\n",
      "        [ 0.1692, -0.2649,  0.2453,  0.0463, -0.1025, -0.1586,  0.1824,  0.2910,\n",
      "         -0.1639, -0.2941],\n",
      "        [-0.0341,  0.2763,  0.1275,  0.1339, -0.1706, -0.3065,  0.0030, -0.1103,\n",
      "         -0.0459, -0.1728],\n",
      "        [-0.2073,  0.2173, -0.1176, -0.2079,  0.1630,  0.1456, -0.1936,  0.1190,\n",
      "         -0.1699, -0.1734],\n",
      "        [-0.0261,  0.1540,  0.1167,  0.2042, -0.2552,  0.0660, -0.0623,  0.2425,\n",
      "          0.2529, -0.0813],\n",
      "        [ 0.0794, -0.0780, -0.0167,  0.1178,  0.0045,  0.1643,  0.1667,  0.1404,\n",
      "          0.1365, -0.2251],\n",
      "        [-0.2298,  0.2280,  0.0936, -0.2533, -0.0540,  0.1553,  0.0902,  0.1526,\n",
      "         -0.1813,  0.1232],\n",
      "        [-0.0205, -0.1868,  0.0425, -0.0830, -0.2424,  0.2934, -0.3118, -0.2923,\n",
      "          0.0387, -0.0714],\n",
      "        [-0.0720, -0.2441, -0.1653, -0.3018, -0.1218,  0.2181,  0.0855,  0.1197,\n",
      "         -0.2796, -0.2257],\n",
      "        [-0.1493,  0.1379,  0.2001, -0.0384,  0.2503, -0.1627, -0.1298, -0.2163,\n",
      "         -0.1059,  0.0622],\n",
      "        [-0.1688,  0.1332, -0.0424, -0.0150, -0.2433,  0.2462, -0.0255, -0.0763,\n",
      "          0.3034,  0.1870]], requires_grad=True)\n",
      "bias_ih_l2 Parameter containing:\n",
      "tensor([-0.2694,  0.1381, -0.1492, -0.2314,  0.0721,  0.2513, -0.2314, -0.0607,\n",
      "         0.1537, -0.2455,  0.1694,  0.2692,  0.2836, -0.0259, -0.0429,  0.0144,\n",
      "         0.2303,  0.0745, -0.1173, -0.2066, -0.1700,  0.1290, -0.0509,  0.2735,\n",
      "         0.0813,  0.3005,  0.0292, -0.1093,  0.0876, -0.3042, -0.2995,  0.2488,\n",
      "         0.0188,  0.0541, -0.2871, -0.0441, -0.2246,  0.2233, -0.2450,  0.0106],\n",
      "       requires_grad=True)\n",
      "bias_hh_l2 Parameter containing:\n",
      "tensor([-8.3834e-05,  3.8115e-02, -3.1506e-02, -1.3021e-01, -8.0019e-02,\n",
      "        -2.3550e-01, -3.5815e-02,  2.3931e-01,  8.6669e-02, -2.5331e-01,\n",
      "        -2.2460e-01,  1.2166e-01,  2.7684e-01, -4.1012e-02, -3.0692e-01,\n",
      "        -1.9929e-01, -2.0707e-01,  2.9462e-01,  2.2659e-01, -1.5928e-01,\n",
      "        -1.5015e-01,  1.8162e-01, -1.8787e-01,  3.1213e-01,  1.5383e-01,\n",
      "        -8.4256e-02, -9.6509e-02, -3.0527e-01, -2.4626e-01, -9.3306e-02,\n",
      "        -2.6313e-01,  2.8731e-01,  3.1556e-01, -3.0169e-01,  1.0752e-01,\n",
      "        -8.7005e-02, -1.6749e-01,  1.4620e-01,  2.6807e-01, -1.3480e-02],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=4, hidden_size=10, num_layers=3, batch_first = True)\n",
    "len(list(lstm.parameters()))\n",
    "#lstm.state_dict()\n",
    "\n",
    "for i in lstm.named_parameters():\n",
    "    if 'weight_ih' in i[0]:\n",
    "        print('Weights for Input data')\n",
    "        print('Weights for 3-gates+1_New_Context for input data:\\n\\t\\t i_gate, f_gate, o_gate, nc_creation:',i[0], i[1].shape)\n",
    "        print()\n",
    "    if 'weight_hh' in i[0]:\n",
    "        print('Weights for previous hidden data')\n",
    "        print('3-gates+1_New_Context weights for previous hidden data:\\n\\t\\t i_gate, f_gate, o_gate, nc_creation:',i[0], i[1].shape)\n",
    "        print()\n",
    "        \n",
    "    if 'bias_ih' in i[0]:\n",
    "        print('bias for input data:', i[0], i[1].shape)\n",
    "    if 'bias_hh' in i[0]:\n",
    "        print('bias for previous hidden data:', i[0], i[1].shape)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "for i in lstm.named_parameters():\n",
    "    print(i[0], i[1].shape)\n",
    "\n",
    "print()\n",
    "\n",
    "for i in lstm.named_parameters():\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-0947b12e0eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n\u001b[0m\u001b[1;32m      3\u001b[0m      weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "weights = next(lstm.parameters()).data\n",
    "h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
    "     weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 4])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = next(lstm.parameters()).data\n",
    "type(t)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About LSTM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_output=  torch.Size([1, 50, 100])\n",
      "hidden_state =  torch.Size([1, 1, 100])\n",
      "cell_state =  torch.Size([1, 1, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hidden_size = 100\n",
    "lstm = nn.LSTM(input_size=40, #the is the size of the embedding per word, not the length of sentence. \n",
    "               hidden_size = my_hidden_size, \n",
    "               num_layers = 1, batch_first = True)\n",
    "\n",
    "lstm_out, h = lstm(embedded_words)# we could provide initialized value of hidden state and cell state\n",
    "\n",
    "# output contains hidden_size vector generated for each input word of the sentence\n",
    "# input was: torch.Size([1, 60, 50])\n",
    "# output is: torch.Size([1, 60, 100])\n",
    "print('lstm_output= ', lstm_out.shape) #(seq_len, batch, num_directions * hidden_size)\n",
    "\n",
    "\n",
    "# these are the output of hidden vector and cell vector\n",
    "# There is one output for each layer\n",
    "# The output is restricted to last time step or for the last word\n",
    "# h_n and c_n of each layer of the last time step t=seq_len\n",
    "\n",
    "\n",
    "#h[0].shape # hidden # torch.Size([1, 1, 100])\n",
    "#h[1].shape # cell   # torch.Size([1, 1, 100])\n",
    "\n",
    "\n",
    "print('hidden_state = ', h[0].shape) # (num_layers * num_directions, batch, hidden_size): torch.Size([1, 1, 100])\n",
    "print('cell_state = ', h[1].shape) # (num_layers * num_directions, batch, hidden_size): torch.Size([1, 1, 100])\n",
    "\n",
    "\n",
    "sum(sum(lstm_out[0,-1] == h[0][-1])) # the last output lstm_ matches with hidden output of the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lstm_out.shape\n",
    "lstm_out.contiguous().view(-1, my_hidden_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear layer\n",
    "my_output = 1\n",
    "fc = nn.Linear(my_hidden_size, my_output)\n",
    "fc_output = fc(lstm_out)\n",
    "fc_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "sigmoid_out = sigmoid(fc_output) \n",
    "sigmoid_out.shape\n",
    "my_batch_size = 1\n",
    "sigmoid_out.view(my_batch_size, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5187]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_out[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://learning.oreilly.com/library/view/hands-on-natural-language/9781789802740/B12365_05_Final_JC_ePub.xhtml\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, n_hidden, n_output, n_layers, drop_p = 0.8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_vocab = n_vocab  # num of input to first layer\n",
    "        self.n_layers = n_layers  # #number of LSTM layers\n",
    "        self.n_hidden = n_hidden  # size of vector of hidden output# 'LSTM Hidden units' in onenote\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed) # number of embedding dimension\n",
    "        \n",
    "                            \n",
    "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, dropout = drop_p)\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward (self, input_words):\n",
    "                          \n",
    "        embedded_words = self.embedding(input_words) # vect size of unique words len. convert to embed size\n",
    "        lstm_out, h = self.lstm(embedded_words) # \n",
    "        lstm_out = self.dropout(lstm_out) # shape is torch.Size([1, 50, 100])\n",
    "        # following line will convert (1 sentence, 50 embeded vector, 100 hidden output for each embed word)\n",
    "        # to (50 embeded vector, 100 hidden output for each embed word)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden) # torch.Size([50, 100])\n",
    "        fc_out = self.fc(lstm_out)    # torch.Size([1, 50, 1])               \n",
    "        sigmoid_out = self.sigmoid(fc_out)   # torch.Size([1, 50, 1])             \n",
    "        sigmoid_out = sigmoid_out.view(batch_size, -1)   # torch.Size([1, 50]) here batch_size is 1\n",
    "        \n",
    "        sigmoid_last = sigmoid_out[:, -1] # out of n_embed values, pick the last one\n",
    "        \n",
    "        return sigmoid_last, h\n",
    "    \n",
    "    \n",
    "    def init_hidden (self, batch_size):\n",
    "        \n",
    "        device = \"cpu\"\n",
    "        weights = next(self.parameters()).data # total length will 4_set_of_parameters x layers\n",
    "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
    "             weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_vocab = len(word_to_int_dict)\n",
    "n_embed = 50 # the final number of dimension in embedded vector\n",
    "n_hidden = 100\n",
    "n_output = 1\n",
    "n_layers = 2\n",
    "\n",
    "sentiment_lstm = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(sentiment_lstm.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most importantly, we define our loss function as binary cross entropy (as we are dealing \n",
    "# with predicting a single binary class) and we define our optimizer to be Adam with \n",
    "# a learning rate of 0.001. We also define our model to run for a short number of epochs \n",
    "# (to save time) and set clip = 5 to define our gradient clipping:\n",
    "\n",
    "print_every = 2400\n",
    "step = 0\n",
    "n_epochs = 1\n",
    "clip = 5  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch ====================  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ardhendusingh/Applications/anaconda3/envs/local_nmt/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/Users/ardhendusingh/Applications/anaconda3/envs/local_nmt/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-8d94e7e64160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print('Epoch ==================== ',epoch)\n",
    "    #hidden_initialized = sentiment_lstm.init_hidden(batch_size)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        step += 1  \n",
    "        sentiment_lstm.zero_grad()\n",
    "        output, h = sentiment_lstm(inputs)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        _= nn.utils.clip_grad_norm(sentiment_lstm.parameters(), clip);\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (step % print_every) == 0:            \n",
    "            net.eval();\n",
    "            valid_losses = []\n",
    "\n",
    "            for v_inputs, v_labels in valid_loader:\n",
    "                       \n",
    "                v_output, v_h = net(v_inputs)\n",
    "                v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "                valid_losses.append(v_loss.item())\n",
    "\n",
    "            print(\"\\t\\t\\tEpoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "                  \"Step: {}\".format(step),\n",
    "                  \"Training Loss: {:.4f}\".format(loss.item()),\n",
    "                  \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
    "            net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), 'model.pkl')\n",
    "#net = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)\n",
    "#net.load_state_dict(torch.load('model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    test_output, test_h = net(inputs)\n",
    "    loss = criterion(test_output, labels)\n",
    "    test_losses.append(loss.item())\n",
    "    \n",
    "    preds = torch.round(test_output.squeeze())\n",
    "    correct_tensor = preds.eq(labels.float().view_as(preds))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "    \n",
    "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
    "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(review):\n",
    "    review = review.translate(str.maketrans('', '', punctuation)).lower().rstrip()\n",
    "    tokenized = word_tokenize(review)\n",
    "    if len(tokenized) >= 50:\n",
    "        review = tokenized[:50]\n",
    "    else:\n",
    "        review= ['0']*(50-len(tokenized)) + tokenized\n",
    "    \n",
    "    final = []\n",
    "    \n",
    "    for token in review:\n",
    "        try:\n",
    "            final.append(word_to_int_dict[token])\n",
    "            \n",
    "        except:\n",
    "            final.append(word_to_int_dict[''])\n",
    "        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "    net.eval()\n",
    "    words = np.array([preprocess_review(review)])\n",
    "    padded_words = torch.from_numpy(words)\n",
    "    pred_loader = DataLoader(padded_words, batch_size = 1, shuffle = True)\n",
    "    for x in pred_loader:\n",
    "        output = net(x)[0].item()\n",
    "    \n",
    "    msg = \"This is a positive review.\" if output >= 0.5 else \"This is a negative review.\"\n",
    "    print(msg)\n",
    "    print('Prediction = ' + str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"The film was good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"It was not good\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NMT",
   "language": "python",
   "name": "nmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
